{"cells":[{"cell_type":"markdown","metadata":{"id":"rhfdl5NBHqE9"},"source":["# Import Library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5793,"status":"ok","timestamp":1706581498167,"user":{"displayName":"- IGETS","userId":"03450291049339902843"},"user_tz":-480},"id":"6cQm8ydOHvEn","outputId":"41d3c239-8ee5-410d-815d-54f8debac9f7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["keras.src.optimizers.adam.Adam"]},"metadata":{},"execution_count":1}],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import shutil\n","import glob\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score\n","from sklearn.utils import shuffle\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","keras.optimizers.Adam"]},{"cell_type":"markdown","metadata":{"id":"rXEONerwAy0s"},"source":["# Mengakses Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3287,"status":"ok","timestamp":1706583870917,"user":{"displayName":"- IGETS","userId":"03450291049339902843"},"user_tz":-480},"id":"GSCR3u_yMRU3","outputId":"6f3c0320-9ffd-44fa-bf21-5a840a57a69f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","ls: cannot access '/content/drive/My Drive/Tugas Akhir/dataset/dataset 2': No such file or directory\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","base_dir = '/content/drive/My Drive/Tugas Akhir/dataset/dataset 1'\n","!ls \"/content/drive/My Drive/Tugas Akhir/dataset/dataset 1\""]},{"cell_type":"markdown","metadata":{"id":"MyyJpXk1SBMz"},"source":["# Menampilkan jumlah dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"executionInfo":{"elapsed":750,"status":"error","timestamp":1706583876873,"user":{"displayName":"- IGETS","userId":"03450291049339902843"},"user_tz":-480},"id":"UqxBZEiUSCr_","outputId":"e9014eda-dcd0-4aa9-f28e-47821f6ab727"},"outputs":[{"output_type":"stream","name":"stdout","text":["Jumlah Citra Asli\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/My Drive/Tugas Akhir/dataset/dataset 2/cataract/'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-7ded341b2dff>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jumlah Citra Asli\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Jumlah dataset Cataract : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcataract_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Jumlah dataset Normal : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Tugas Akhir/dataset/dataset 2/cataract/'"]}],"source":["cataract_dir = os.path.join(base_dir, 'cataract/')\n","normal_dir = os.path.join(base_dir, 'normal/')\n","\n","print(\"Jumlah Citra Asli\")\n","print('Jumlah dataset Cataract : ',len(os.listdir(cataract_dir)))\n","print('Jumlah dataset Normal : ',len(os.listdir(normal_dir)))\n","\n","cataract_augmented = os.path.join(base_dir, 'cataract_augmented/')\n","normal_augmented = os.path.join(base_dir, 'normal_augmented/')\n","\n","print(\" \")\n","print(\"Jumlah Citra Hasil Augmentasi\")\n","print('Jumlah dataset Cataract : ',len(os.listdir(cataract_augmented)))\n","print('Jumlah dataset Normal : ',len(os.listdir(normal_augmented)))\n","\n","# num_cataract = len(os.listdir(cataract_dir))\n","# num_normal = len(os.listdir(normal_dir))\n","\n","# # Menampilkan diagram jumlah\n","# labels = ['Cataract', 'Normal']\n","# values = [num_cataract, num_normal]\n","\n","# plt.bar(labels, values)\n","# plt.xlabel('Kelas')\n","# plt.ylabel('Jumlah')\n","# plt.title('Jumlah Data Setiap Kelas')\n","# plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ygP4fcUDR4yz"},"source":["# Menggabungkan dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YCav0ysHR6Bo"},"outputs":[],"source":["dataset_dir = os.path.join(base_dir, 'dataset')\n","train_dir = os.path.join(base_dir, 'latih')\n","test_dir = os.path.join(base_dir, 'test')\n","validation_dir = os.path.join(base_dir, 'validasi')"]},{"cell_type":"markdown","metadata":{"id":"HKKPoQAz2Xat"},"source":["# Split Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYXR6oMr4TqV"},"outputs":[],"source":["image_paths = []\n","labels = []\n","for label, label_dir in enumerate([cataract_dir, normal_dir, cataract_augmented, normal_augmented]):\n","    for filename in os.listdir(label_dir):\n","        image_paths.append(os.path.join(label_dir, filename))\n","        labels.append(label)\n","\n","train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n","    image_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n","\n","# num_train_val = len(train_val_paths)\n","# num_test = len(test_paths)\n","\n","# # Menampilkan diagram jumlah split\n","# labels = ['Train/Validation', 'Test']\n","# values = [num_train_val, num_test]\n","# plt.bar(labels, values)\n","# plt.xlabel('Split')\n","# plt.ylabel('Jumlah')\n","# plt.title('Jumlah Hasil Split')\n","# plt.show()\n","\n","def my_metrics(y_true, y_pred):\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n","    f1_Score = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n","    print(\"Accuracy  : {}\".format(accuracy))\n","    print(\"Precision : {}\".format(precision))\n","    print(\"f1Score : {}\".format(f1_Score))\n","    cm = confusion_matrix(y_true, y_pred)\n","    print(cm)\n","    return accuracy, precision, f1_Score"]},{"cell_type":"markdown","metadata":{"id":"ITR2mvNo5zme"},"source":["# Pembuatan Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHnhJtLKakh-"},"outputs":[],"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(4, activation='softmax'),\n","])"]},{"cell_type":"markdown","metadata":{"id":"Z9Ro86ildHVf"},"source":["# Compile"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1694049126780,"user":{"displayName":"murmayasa 2","userId":"06759457837881550460"},"user_tz":-480},"id":"Y9lj5cJtdIju","outputId":"a682a209-9970-45ec-cfd3-fba981b8cfca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_5 (Dropout)         (None, 74, 74, 32)        0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_6 (Dropout)         (None, 36, 36, 64)        0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_7 (Dropout)         (None, 17, 17, 128)       0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 15, 15, 512)       590336    \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 7, 7, 512)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_8 (Dropout)         (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 25088)             0         \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               12845568  \n","                                                                 \n"," dropout_9 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 4)                 2052      \n","                                                                 \n","=================================================================\n","Total params: 13,531,204\n","Trainable params: 13,531,204\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["learning_rate = 0.001\n","model.compile(loss='categorical_crossentropy',\n","        optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n","        metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"O5yJSFPkcZj2"},"source":["# Preprocessing dan Augmentasi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYBONAOO8CsB"},"outputs":[],"source":["dataset_path = \"/content/drive/My Drive/Tugas Akhir/dataset/dataset 1/normal\"\n","augmented_paths = \"/content/drive/My Drive/Tugas Akhir/dataset/dataset 1/normal_augmented\"\n","\n","if not os.path.exists(augmented_paths):\n","    os.mkdir(augmented_paths)\n","\n","#Konfigurasi augmentasi\n","train_datagen = ImageDataGenerator(\n","    # rescale=1./225,\n","    # brightness_range=[0.5, 1.0],\n","    # horizontal_flip=True,\n","    # vertical_flip=True,\n","    # shear_range=0.2,\n","    # rotation_range=45,\n","    # fill_mode='mirror',\n",")\n","\n","# image_files = []\n","# for root, dirs, files in os.walk(dataset_path):\n","#     for file in files:\n","#         if file.endswith((\".jpg\", \".png\")):\n","#             image_files.append(os.path.join(root, file))\n","\n","# # Augmentasi dan menyimpan setiap citra\n","# for image_file in image_files:\n","#     img = cv2.imread(image_file)\n","#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Ubah warna citra jika diperlukan\n","\n","#     # Koreksi gamma dengan nilai gamma yang diinginkan (misal: 1.5)\n","#     gamma_value = 1.5\n","#     img = adjust_gamma(img, gamma=gamma_value)\n","\n","#     # Resize citra jika diperlukan\n","#     img = cv2.resize(img, (150, 150))\n","\n","#     # Mengubah dimensi citra menjadi bentuk (1, height, width, channels)\n","#     img = np.expand_dims(img, axis=0)\n","\n","#     # Dapatkan nama file asli\n","#     original_filename = os.path.basename(image_file)\n","\n","#     # Membuat iterator augmentasi\n","#     aug_iter = train_datagen.flow(img, save_to_dir=augmented_paths, save_prefix=original_filename[:-4])\n","\n","#     # Mendapatkan ekstensi citra asli\n","#     extension = os.path.splitext(original_filename)\n","\n","#     # Melakukan augmentasi dan menyimpan citra\n","#     for i in range(1):\n","#         augmented_img = next(aug_iter)\n","#         # Menyimpan citra dengan ekstensi yang sama seperti citra asli\n","#         augmented_filename = f\"{original_filename[:-4]}augmented{i}{extension[1]}\"\n","#         cv2.imwrite(os.path.join(augmented_paths, augmented_filename), cv2.cvtColor(augmented_img[0], cv2.COLOR_RGB2BGR))"]},{"cell_type":"markdown","metadata":{"id":"4vSSH7OBQTf2"},"source":["# Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uj5CXnoEXXf4","executionInfo":{"status":"ok","timestamp":1694052586273,"user_tz":-480,"elapsed":2517722,"user":{"displayName":"murmayasa 2","userId":"06759457837881550460"}},"outputId":"8e1f4f3c-060e-4888-d3fc-7a694530f791"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil Fold :  1\n","Found 4054 validated image filenames belonging to 4 classes.\n","Found 1268 validated image filenames belonging to 4 classes.\n","Epoch 1/25\n","127/127 - 24s - loss: 16.6112 - accuracy: 0.4378 - val_loss: 0.9932 - val_accuracy: 0.5221 - 24s/epoch - 192ms/step\n","Epoch 2/25\n","127/127 - 20s - loss: 0.9145 - accuracy: 0.5557 - val_loss: 0.8281 - val_accuracy: 0.5552 - 20s/epoch - 161ms/step\n","Epoch 3/25\n","127/127 - 22s - loss: 0.7488 - accuracy: 0.6085 - val_loss: 0.6759 - val_accuracy: 0.6073 - 22s/epoch - 172ms/step\n","Epoch 4/25\n","127/127 - 22s - loss: 0.6884 - accuracy: 0.6455 - val_loss: 0.6584 - val_accuracy: 0.6341 - 22s/epoch - 172ms/step\n","Epoch 5/25\n","127/127 - 21s - loss: 0.6558 - accuracy: 0.6660 - val_loss: 0.6356 - val_accuracy: 0.6593 - 21s/epoch - 165ms/step\n","Epoch 6/25\n","127/127 - 21s - loss: 0.6066 - accuracy: 0.6961 - val_loss: 0.5608 - val_accuracy: 0.7295 - 21s/epoch - 164ms/step\n","Epoch 7/25\n","127/127 - 20s - loss: 0.5750 - accuracy: 0.7089 - val_loss: 0.5576 - val_accuracy: 0.7208 - 20s/epoch - 161ms/step\n","Epoch 8/25\n","127/127 - 21s - loss: 0.5694 - accuracy: 0.7178 - val_loss: 0.7075 - val_accuracy: 0.6893 - 21s/epoch - 168ms/step\n","Epoch 9/25\n","127/127 - 21s - loss: 0.5105 - accuracy: 0.7551 - val_loss: 0.6179 - val_accuracy: 0.7177 - 21s/epoch - 163ms/step\n","Epoch 10/25\n","127/127 - 22s - loss: 0.5378 - accuracy: 0.7491 - val_loss: 0.5315 - val_accuracy: 0.7326 - 22s/epoch - 170ms/step\n","Epoch 11/25\n","127/127 - 21s - loss: 0.5156 - accuracy: 0.7585 - val_loss: 0.4784 - val_accuracy: 0.7768 - 21s/epoch - 167ms/step\n","Epoch 12/25\n","127/127 - 22s - loss: 0.4822 - accuracy: 0.7790 - val_loss: 0.4751 - val_accuracy: 0.7839 - 22s/epoch - 176ms/step\n","Epoch 13/25\n","127/127 - 26s - loss: 0.4914 - accuracy: 0.7763 - val_loss: 0.5850 - val_accuracy: 0.7445 - 26s/epoch - 208ms/step\n","Epoch 14/25\n","127/127 - 21s - loss: 0.5501 - accuracy: 0.7694 - val_loss: 0.4891 - val_accuracy: 0.7934 - 21s/epoch - 163ms/step\n","Epoch 15/25\n","127/127 - 21s - loss: 0.4357 - accuracy: 0.8049 - val_loss: 0.5097 - val_accuracy: 0.7792 - 21s/epoch - 166ms/step\n","Epoch 16/25\n","127/127 - 22s - loss: 0.4226 - accuracy: 0.8019 - val_loss: 0.5383 - val_accuracy: 0.7618 - 22s/epoch - 170ms/step\n","Epoch 17/25\n","127/127 - 20s - loss: 0.4238 - accuracy: 0.8071 - val_loss: 0.4770 - val_accuracy: 0.7792 - 20s/epoch - 161ms/step\n","Epoch 18/25\n","127/127 - 21s - loss: 0.4019 - accuracy: 0.8098 - val_loss: 0.5401 - val_accuracy: 0.7729 - 21s/epoch - 168ms/step\n","Epoch 19/25\n","127/127 - 22s - loss: 0.3965 - accuracy: 0.8249 - val_loss: 0.5082 - val_accuracy: 0.7831 - 22s/epoch - 174ms/step\n","Epoch 20/25\n","127/127 - 21s - loss: 0.4362 - accuracy: 0.8059 - val_loss: 0.5012 - val_accuracy: 0.7784 - 21s/epoch - 165ms/step\n","Epoch 21/25\n","127/127 - 22s - loss: 0.3945 - accuracy: 0.8256 - val_loss: 0.4486 - val_accuracy: 0.7989 - 22s/epoch - 175ms/step\n","Epoch 22/25\n","127/127 - 22s - loss: 0.3563 - accuracy: 0.8389 - val_loss: 0.4605 - val_accuracy: 0.8028 - 22s/epoch - 176ms/step\n","Epoch 23/25\n","127/127 - 21s - loss: 0.3605 - accuracy: 0.8407 - val_loss: 0.4578 - val_accuracy: 0.7902 - 21s/epoch - 163ms/step\n","Epoch 24/25\n","127/127 - 22s - loss: 0.3751 - accuracy: 0.8328 - val_loss: 0.4615 - val_accuracy: 0.7894 - 22s/epoch - 169ms/step\n","Epoch 25/25\n","127/127 - 20s - loss: 0.3504 - accuracy: 0.8483 - val_loss: 0.4904 - val_accuracy: 0.7942 - 20s/epoch - 160ms/step\n","40/40 [==============================] - 6s 142ms/step\n","*** Performance on Validation data ***\n","Accuracy  : 0.7941640378548895\n","Precision : 0.804613231787068\n","f1Score : 0.7930428411395934\n","[[151  55   2   0]\n"," [  4 210   0   1]\n"," [  0   0 340  75]\n"," [  0   0 124 306]]\n","Hasil Fold :  2\n","Found 4055 validated image filenames belonging to 4 classes.\n","Found 1267 validated image filenames belonging to 4 classes.\n","Epoch 1/25\n","127/127 - 22s - loss: 0.3920 - accuracy: 0.8234 - val_loss: 0.3427 - val_accuracy: 0.8508 - 22s/epoch - 171ms/step\n","Epoch 2/25\n","127/127 - 21s - loss: 0.3843 - accuracy: 0.8301 - val_loss: 0.3647 - val_accuracy: 0.8421 - 21s/epoch - 168ms/step\n","Epoch 3/25\n","127/127 - 22s - loss: 0.3672 - accuracy: 0.8330 - val_loss: 0.3941 - val_accuracy: 0.8366 - 22s/epoch - 172ms/step\n","Epoch 4/25\n","127/127 - 20s - loss: 0.3493 - accuracy: 0.8392 - val_loss: 0.3946 - val_accuracy: 0.8161 - 20s/epoch - 161ms/step\n","Epoch 5/25\n","127/127 - 21s - loss: 0.3441 - accuracy: 0.8481 - val_loss: 0.3706 - val_accuracy: 0.8311 - 21s/epoch - 169ms/step\n","Epoch 6/25\n","127/127 - 21s - loss: 0.3160 - accuracy: 0.8533 - val_loss: 0.4213 - val_accuracy: 0.8177 - 21s/epoch - 169ms/step\n","Epoch 7/25\n","127/127 - 22s - loss: 0.3344 - accuracy: 0.8503 - val_loss: 0.3593 - val_accuracy: 0.8343 - 22s/epoch - 174ms/step\n","Epoch 8/25\n","127/127 - 21s - loss: 0.3236 - accuracy: 0.8543 - val_loss: 0.3944 - val_accuracy: 0.8193 - 21s/epoch - 167ms/step\n","Epoch 9/25\n","127/127 - 20s - loss: 0.3011 - accuracy: 0.8565 - val_loss: 0.3675 - val_accuracy: 0.8414 - 20s/epoch - 161ms/step\n","Epoch 10/25\n","127/127 - 21s - loss: 0.3113 - accuracy: 0.8547 - val_loss: 0.4064 - val_accuracy: 0.8335 - 21s/epoch - 166ms/step\n","Epoch 11/25\n","127/127 - 20s - loss: 0.3440 - accuracy: 0.8449 - val_loss: 0.4438 - val_accuracy: 0.7995 - 20s/epoch - 157ms/step\n","Epoch 12/25\n","127/127 - 21s - loss: 0.3289 - accuracy: 0.8412 - val_loss: 0.4205 - val_accuracy: 0.8240 - 21s/epoch - 165ms/step\n","Epoch 13/25\n","127/127 - 21s - loss: 0.3387 - accuracy: 0.8404 - val_loss: 0.5343 - val_accuracy: 0.7514 - 21s/epoch - 165ms/step\n","Epoch 14/25\n","127/127 - 21s - loss: 0.3261 - accuracy: 0.8476 - val_loss: 0.4484 - val_accuracy: 0.8137 - 21s/epoch - 164ms/step\n","Epoch 15/25\n","127/127 - 21s - loss: 0.3282 - accuracy: 0.8515 - val_loss: 0.4007 - val_accuracy: 0.8382 - 21s/epoch - 165ms/step\n","Epoch 16/25\n","127/127 - 20s - loss: 0.2971 - accuracy: 0.8535 - val_loss: 0.4288 - val_accuracy: 0.8200 - 20s/epoch - 160ms/step\n","Epoch 17/25\n","127/127 - 21s - loss: 0.2940 - accuracy: 0.8562 - val_loss: 0.4041 - val_accuracy: 0.8216 - 21s/epoch - 165ms/step\n","Epoch 18/25\n","127/127 - 20s - loss: 0.2805 - accuracy: 0.8651 - val_loss: 0.4199 - val_accuracy: 0.8303 - 20s/epoch - 158ms/step\n","Epoch 19/25\n","127/127 - 21s - loss: 0.2873 - accuracy: 0.8636 - val_loss: 0.4462 - val_accuracy: 0.8295 - 21s/epoch - 163ms/step\n","Epoch 20/25\n","127/127 - 21s - loss: 0.3124 - accuracy: 0.8530 - val_loss: 0.4390 - val_accuracy: 0.8019 - 21s/epoch - 165ms/step\n","Epoch 21/25\n","127/127 - 21s - loss: 0.2738 - accuracy: 0.8666 - val_loss: 0.4608 - val_accuracy: 0.8161 - 21s/epoch - 163ms/step\n","Epoch 22/25\n","127/127 - 21s - loss: 0.2642 - accuracy: 0.8668 - val_loss: 0.4442 - val_accuracy: 0.8114 - 21s/epoch - 166ms/step\n","Epoch 23/25\n","127/127 - 21s - loss: 0.2892 - accuracy: 0.8629 - val_loss: 0.3941 - val_accuracy: 0.8232 - 21s/epoch - 164ms/step\n","Epoch 24/25\n","127/127 - 20s - loss: 0.2742 - accuracy: 0.8651 - val_loss: 0.4804 - val_accuracy: 0.8043 - 20s/epoch - 160ms/step\n","Epoch 25/25\n","127/127 - 21s - loss: 0.2943 - accuracy: 0.8671 - val_loss: 0.5189 - val_accuracy: 0.8129 - 21s/epoch - 163ms/step\n","40/40 [==============================] - 4s 109ms/step\n","*** Performance on Validation data ***\n","Accuracy  : 0.8129439621152328\n","Precision : 0.8197973608259261\n","f1Score : 0.8120327473910719\n","[[154  54   0   0]\n"," [  3 212   0   0]\n"," [  2   1 322  90]\n"," [  0   1  86 342]]\n","Hasil Fold :  3\n","Found 4055 validated image filenames belonging to 4 classes.\n","Found 1267 validated image filenames belonging to 4 classes.\n","Epoch 1/25\n","127/127 - 22s - loss: 0.3824 - accuracy: 0.8284 - val_loss: 0.3575 - val_accuracy: 0.8445 - 22s/epoch - 171ms/step\n","Epoch 2/25\n","127/127 - 21s - loss: 0.3069 - accuracy: 0.8587 - val_loss: 0.2955 - val_accuracy: 0.8635 - 21s/epoch - 164ms/step\n","Epoch 3/25\n","127/127 - 20s - loss: 0.2925 - accuracy: 0.8609 - val_loss: 0.3633 - val_accuracy: 0.8524 - 20s/epoch - 160ms/step\n","Epoch 4/25\n","127/127 - 21s - loss: 0.2965 - accuracy: 0.8619 - val_loss: 0.2996 - val_accuracy: 0.8516 - 21s/epoch - 164ms/step\n","Epoch 5/25\n","127/127 - 20s - loss: 0.2690 - accuracy: 0.8720 - val_loss: 0.2891 - val_accuracy: 0.8674 - 20s/epoch - 157ms/step\n","Epoch 6/25\n","127/127 - 21s - loss: 0.2478 - accuracy: 0.8727 - val_loss: 0.3240 - val_accuracy: 0.8524 - 21s/epoch - 163ms/step\n","Epoch 7/25\n","127/127 - 20s - loss: 0.2686 - accuracy: 0.8671 - val_loss: 0.3145 - val_accuracy: 0.8548 - 20s/epoch - 158ms/step\n","Epoch 8/25\n","127/127 - 21s - loss: 0.3017 - accuracy: 0.8683 - val_loss: 0.3553 - val_accuracy: 0.8414 - 21s/epoch - 164ms/step\n","Epoch 9/25\n","127/127 - 20s - loss: 0.3468 - accuracy: 0.8538 - val_loss: 0.3839 - val_accuracy: 0.8579 - 20s/epoch - 158ms/step\n","Epoch 10/25\n","127/127 - 21s - loss: 0.2718 - accuracy: 0.8678 - val_loss: 0.3713 - val_accuracy: 0.8279 - 21s/epoch - 164ms/step\n","Epoch 11/25\n","127/127 - 20s - loss: 0.2630 - accuracy: 0.8769 - val_loss: 0.3797 - val_accuracy: 0.8343 - 20s/epoch - 161ms/step\n","Epoch 12/25\n","127/127 - 21s - loss: 0.2448 - accuracy: 0.8782 - val_loss: 0.3573 - val_accuracy: 0.8587 - 21s/epoch - 166ms/step\n","Epoch 13/25\n","127/127 - 21s - loss: 0.2729 - accuracy: 0.8671 - val_loss: 0.3809 - val_accuracy: 0.8500 - 21s/epoch - 167ms/step\n","Epoch 14/25\n","127/127 - 21s - loss: 0.2534 - accuracy: 0.8718 - val_loss: 0.3441 - val_accuracy: 0.8579 - 21s/epoch - 166ms/step\n","Epoch 15/25\n","127/127 - 22s - loss: 0.2465 - accuracy: 0.8829 - val_loss: 0.3871 - val_accuracy: 0.8437 - 22s/epoch - 171ms/step\n","Epoch 16/25\n","127/127 - 21s - loss: 0.2407 - accuracy: 0.8824 - val_loss: 0.3549 - val_accuracy: 0.8603 - 21s/epoch - 165ms/step\n","Epoch 17/25\n","127/127 - 21s - loss: 0.2459 - accuracy: 0.8811 - val_loss: 0.3624 - val_accuracy: 0.8493 - 21s/epoch - 167ms/step\n","Epoch 18/25\n","127/127 - 21s - loss: 0.2376 - accuracy: 0.8787 - val_loss: 0.3537 - val_accuracy: 0.8469 - 21s/epoch - 166ms/step\n","Epoch 19/25\n","127/127 - 21s - loss: 0.2490 - accuracy: 0.8735 - val_loss: 0.4042 - val_accuracy: 0.8414 - 21s/epoch - 167ms/step\n","Epoch 20/25\n","127/127 - 22s - loss: 0.2294 - accuracy: 0.8819 - val_loss: 0.4425 - val_accuracy: 0.8264 - 22s/epoch - 170ms/step\n","Epoch 21/25\n","127/127 - 21s - loss: 0.2327 - accuracy: 0.8893 - val_loss: 0.3617 - val_accuracy: 0.8635 - 21s/epoch - 166ms/step\n","Epoch 22/25\n","127/127 - 21s - loss: 0.2214 - accuracy: 0.8935 - val_loss: 0.3794 - val_accuracy: 0.8461 - 21s/epoch - 163ms/step\n","Epoch 23/25\n","127/127 - 21s - loss: 0.2475 - accuracy: 0.8742 - val_loss: 0.3817 - val_accuracy: 0.8532 - 21s/epoch - 165ms/step\n","Epoch 24/25\n","127/127 - 21s - loss: 0.2494 - accuracy: 0.8804 - val_loss: 0.4345 - val_accuracy: 0.8366 - 21s/epoch - 166ms/step\n","Epoch 25/25\n","127/127 - 21s - loss: 0.2105 - accuracy: 0.8912 - val_loss: 0.4527 - val_accuracy: 0.8232 - 21s/epoch - 163ms/step\n","40/40 [==============================] - 4s 108ms/step\n","*** Performance on Validation data ***\n","Accuracy  : 0.8232044198895028\n","Precision : 0.8344200282587363\n","f1Score : 0.8221807982886674\n","[[202   4   2   0]\n"," [ 67 147   0   0]\n"," [  1   0 349  66]\n"," [  0   1  83 345]]\n","Hasil Fold :  4\n","Found 4055 validated image filenames belonging to 4 classes.\n","Found 1267 validated image filenames belonging to 4 classes.\n","Epoch 1/25\n","127/127 - 22s - loss: 0.3198 - accuracy: 0.8617 - val_loss: 0.2026 - val_accuracy: 0.9132 - 22s/epoch - 170ms/step\n","Epoch 2/25\n","127/127 - 25s - loss: 0.2415 - accuracy: 0.8868 - val_loss: 0.1942 - val_accuracy: 0.9195 - 25s/epoch - 198ms/step\n","Epoch 3/25\n","127/127 - 25s - loss: 0.2468 - accuracy: 0.8912 - val_loss: 0.2244 - val_accuracy: 0.9077 - 25s/epoch - 199ms/step\n","Epoch 4/25\n","127/127 - 25s - loss: 0.2267 - accuracy: 0.8974 - val_loss: 0.2129 - val_accuracy: 0.9108 - 25s/epoch - 198ms/step\n","Epoch 5/25\n","127/127 - 25s - loss: 0.2264 - accuracy: 0.8885 - val_loss: 0.2158 - val_accuracy: 0.9061 - 25s/epoch - 200ms/step\n","Epoch 6/25\n","127/127 - 21s - loss: 0.2312 - accuracy: 0.8962 - val_loss: 0.1980 - val_accuracy: 0.9132 - 21s/epoch - 165ms/step\n","Epoch 7/25\n","127/127 - 26s - loss: 0.2017 - accuracy: 0.9033 - val_loss: 0.2673 - val_accuracy: 0.8816 - 26s/epoch - 205ms/step\n","Epoch 8/25\n","127/127 - 21s - loss: 0.1972 - accuracy: 0.9038 - val_loss: 0.2011 - val_accuracy: 0.8887 - 21s/epoch - 162ms/step\n","Epoch 9/25\n","127/127 - 21s - loss: 0.2102 - accuracy: 0.8969 - val_loss: 0.2594 - val_accuracy: 0.8966 - 21s/epoch - 166ms/step\n","Epoch 10/25\n","127/127 - 25s - loss: 0.2363 - accuracy: 0.9033 - val_loss: 0.2920 - val_accuracy: 0.8745 - 25s/epoch - 200ms/step\n","Epoch 11/25\n","127/127 - 21s - loss: 0.2320 - accuracy: 0.8964 - val_loss: 0.2805 - val_accuracy: 0.8950 - 21s/epoch - 165ms/step\n","Epoch 12/25\n","127/127 - 20s - loss: 0.2586 - accuracy: 0.8917 - val_loss: 0.2385 - val_accuracy: 0.8998 - 20s/epoch - 159ms/step\n","Epoch 13/25\n","127/127 - 22s - loss: 0.1864 - accuracy: 0.9092 - val_loss: 0.2277 - val_accuracy: 0.8998 - 22s/epoch - 171ms/step\n","Epoch 14/25\n","127/127 - 21s - loss: 0.1774 - accuracy: 0.9181 - val_loss: 0.2382 - val_accuracy: 0.9006 - 21s/epoch - 164ms/step\n","Epoch 15/25\n","127/127 - 21s - loss: 0.1853 - accuracy: 0.9060 - val_loss: 0.2549 - val_accuracy: 0.8911 - 21s/epoch - 164ms/step\n","Epoch 16/25\n","127/127 - 20s - loss: 0.1989 - accuracy: 0.9105 - val_loss: 0.2682 - val_accuracy: 0.8974 - 20s/epoch - 157ms/step\n","Epoch 17/25\n","127/127 - 21s - loss: 0.1901 - accuracy: 0.9181 - val_loss: 0.2221 - val_accuracy: 0.9100 - 21s/epoch - 165ms/step\n","Epoch 18/25\n","127/127 - 21s - loss: 0.1711 - accuracy: 0.9223 - val_loss: 0.2505 - val_accuracy: 0.8974 - 21s/epoch - 162ms/step\n","Epoch 19/25\n","127/127 - 22s - loss: 0.1589 - accuracy: 0.9243 - val_loss: 0.2377 - val_accuracy: 0.9116 - 22s/epoch - 175ms/step\n","Epoch 20/25\n","127/127 - 21s - loss: 0.1606 - accuracy: 0.9221 - val_loss: 0.2118 - val_accuracy: 0.9116 - 21s/epoch - 163ms/step\n","Epoch 21/25\n","127/127 - 20s - loss: 0.1541 - accuracy: 0.9248 - val_loss: 0.2594 - val_accuracy: 0.9053 - 20s/epoch - 158ms/step\n","Epoch 22/25\n","127/127 - 21s - loss: 0.1691 - accuracy: 0.9189 - val_loss: 0.2883 - val_accuracy: 0.9061 - 21s/epoch - 166ms/step\n","Epoch 23/25\n","127/127 - 25s - loss: 0.2175 - accuracy: 0.9060 - val_loss: 0.3425 - val_accuracy: 0.8658 - 25s/epoch - 200ms/step\n","Epoch 24/25\n","127/127 - 25s - loss: 0.1777 - accuracy: 0.9206 - val_loss: 0.3051 - val_accuracy: 0.8840 - 25s/epoch - 200ms/step\n","Epoch 25/25\n","127/127 - 21s - loss: 0.1712 - accuracy: 0.9236 - val_loss: 0.3198 - val_accuracy: 0.8974 - 21s/epoch - 166ms/step\n","40/40 [==============================] - 5s 133ms/step\n","*** Performance on Validation data ***\n","Accuracy  : 0.8973954222573007\n","Precision : 0.9045368231142276\n","f1Score : 0.8970160559987755\n","[[198   9   0   0]\n"," [ 11 204   0   0]\n"," [ 10   0 391  14]\n"," [  1   1  84 344]]\n","Hasil Fold :  5\n","Found 4055 validated image filenames belonging to 4 classes.\n","Found 1267 validated image filenames belonging to 4 classes.\n","Epoch 1/25\n","127/127 - 21s - loss: 0.2703 - accuracy: 0.9001 - val_loss: 0.1481 - val_accuracy: 0.9298 - 21s/epoch - 164ms/step\n","Epoch 2/25\n","127/127 - 20s - loss: 0.1720 - accuracy: 0.9211 - val_loss: 0.1692 - val_accuracy: 0.9258 - 20s/epoch - 160ms/step\n","Epoch 3/25\n","127/127 - 20s - loss: 0.2005 - accuracy: 0.9115 - val_loss: 0.2760 - val_accuracy: 0.8934 - 20s/epoch - 158ms/step\n","Epoch 4/25\n","127/127 - 21s - loss: 0.1746 - accuracy: 0.9208 - val_loss: 0.1966 - val_accuracy: 0.9187 - 21s/epoch - 167ms/step\n","Epoch 5/25\n","127/127 - 21s - loss: 0.1774 - accuracy: 0.9240 - val_loss: 0.2220 - val_accuracy: 0.9053 - 21s/epoch - 163ms/step\n","Epoch 6/25\n","127/127 - 21s - loss: 0.1716 - accuracy: 0.9191 - val_loss: 0.2278 - val_accuracy: 0.8942 - 21s/epoch - 163ms/step\n","Epoch 7/25\n","127/127 - 21s - loss: 0.1787 - accuracy: 0.9231 - val_loss: 0.2074 - val_accuracy: 0.9132 - 21s/epoch - 163ms/step\n","Epoch 8/25\n","127/127 - 26s - loss: 0.1632 - accuracy: 0.9233 - val_loss: 0.2305 - val_accuracy: 0.8974 - 26s/epoch - 203ms/step\n","Epoch 9/25\n","127/127 - 21s - loss: 0.1597 - accuracy: 0.9233 - val_loss: 0.2169 - val_accuracy: 0.9084 - 21s/epoch - 167ms/step\n","Epoch 10/25\n","127/127 - 21s - loss: 0.1579 - accuracy: 0.9255 - val_loss: 0.2409 - val_accuracy: 0.8998 - 21s/epoch - 164ms/step\n","Epoch 11/25\n","127/127 - 21s - loss: 0.1770 - accuracy: 0.9186 - val_loss: 0.1707 - val_accuracy: 0.9148 - 21s/epoch - 162ms/step\n","Epoch 12/25\n","127/127 - 21s - loss: 0.1772 - accuracy: 0.9233 - val_loss: 0.1999 - val_accuracy: 0.9108 - 21s/epoch - 163ms/step\n","Epoch 13/25\n","127/127 - 20s - loss: 0.1886 - accuracy: 0.9253 - val_loss: 0.2439 - val_accuracy: 0.8958 - 20s/epoch - 158ms/step\n","Epoch 14/25\n","127/127 - 21s - loss: 0.1483 - accuracy: 0.9309 - val_loss: 0.2494 - val_accuracy: 0.9069 - 21s/epoch - 165ms/step\n","Epoch 15/25\n","127/127 - 20s - loss: 0.1523 - accuracy: 0.9280 - val_loss: 0.2672 - val_accuracy: 0.8903 - 20s/epoch - 157ms/step\n","Epoch 16/25\n","127/127 - 21s - loss: 0.1320 - accuracy: 0.9349 - val_loss: 0.2345 - val_accuracy: 0.9132 - 21s/epoch - 164ms/step\n","Epoch 17/25\n","127/127 - 20s - loss: 0.1570 - accuracy: 0.9265 - val_loss: 0.2783 - val_accuracy: 0.8919 - 20s/epoch - 159ms/step\n","Epoch 18/25\n","127/127 - 20s - loss: 0.1622 - accuracy: 0.9322 - val_loss: 0.4116 - val_accuracy: 0.8658 - 20s/epoch - 159ms/step\n","Epoch 19/25\n","127/127 - 22s - loss: 0.1872 - accuracy: 0.9268 - val_loss: 0.2237 - val_accuracy: 0.9187 - 22s/epoch - 171ms/step\n","Epoch 20/25\n","127/127 - 20s - loss: 0.1331 - accuracy: 0.9356 - val_loss: 0.2426 - val_accuracy: 0.9092 - 20s/epoch - 161ms/step\n","Epoch 21/25\n","127/127 - 20s - loss: 0.1441 - accuracy: 0.9329 - val_loss: 0.2433 - val_accuracy: 0.9092 - 20s/epoch - 160ms/step\n","Epoch 22/25\n","127/127 - 20s - loss: 0.2292 - accuracy: 0.9085 - val_loss: 0.2899 - val_accuracy: 0.9037 - 20s/epoch - 160ms/step\n","Epoch 23/25\n","127/127 - 21s - loss: 0.1846 - accuracy: 0.9208 - val_loss: 0.2985 - val_accuracy: 0.8745 - 21s/epoch - 162ms/step\n","Epoch 24/25\n","127/127 - 20s - loss: 0.1505 - accuracy: 0.9290 - val_loss: 0.3058 - val_accuracy: 0.9092 - 20s/epoch - 155ms/step\n","Epoch 25/25\n","127/127 - 20s - loss: 0.1374 - accuracy: 0.9374 - val_loss: 0.2717 - val_accuracy: 0.9029 - 20s/epoch - 161ms/step\n","40/40 [==============================] - 5s 120ms/step\n","*** Performance on Validation data ***\n","Accuracy  : 0.9029202841357538\n","Precision : 0.9123984170023379\n","f1Score : 0.9023362354136334\n","[[203   4   0   0]\n"," [ 18 197   0   0]\n"," [  0   0 403  12]\n"," [  1   0  88 341]]\n"]}],"source":["class_labels = [cataract_dir, normal_dir]\n","skf = StratifiedKFold(n_splits=5, shuffle=True)\n","\n","fold_num = 0\n","test_losses = []\n","test_accuracies = []\n","confusion_matrices = []\n","\n","for train_index, val_index in skf.split(image_paths, labels):\n","    fold_num += 1\n","    print(\"Hasil Fold : \", fold_num)\n","    X_train, X_val = np.array(image_paths)[train_index], np.array(image_paths)[val_index]\n","    Y_train, Y_val = np.array(labels)[train_index], np.array(labels)[val_index]\n","\n","    Y_train = Y_train.astype(str)\n","    Y_val = Y_val.astype(str)\n","\n","    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n","        X_train, Y_train, test_size=0.2, random_state=42, stratify=Y_train\n","    )\n","\n","    for each_index in range(len(X_val)):\n","        class_label = ''\n","        for i in range(len(class_labels)):\n","            if Y_val[each_index] == str(i):\n","                class_label = class_labels[i]\n","        shutil.move(\n","            os.path.join(base_dir, 'latih', class_label, X_val[each_index]),\n","            os.path.join(base_dir, 'validasi', class_label, X_val[each_index])\n","        )\n","\n","    train_generator = train_datagen.flow_from_dataframe(\n","        pd.DataFrame({\"image_path\": train_val_paths, \"label\": train_val_labels}),\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode=\"categorical\",\n","        shuffle=True\n","    )\n","\n","    val_datagen = ImageDataGenerator(\n","        # rescale=1./225\n","        )\n","\n","    val_generator = val_datagen.flow_from_dataframe(\n","        pd.DataFrame({\"image_path\": X_val, \"label\": Y_val}),\n","        x_col=\"image_path\",\n","        y_col=\"label\",\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode=\"categorical\",\n","        shuffle=False\n","    )\n","\n","    # Training Model\n","    history = model.fit(\n","        train_generator,\n","        epochs=25,\n","        steps_per_epoch=len(train_generator),\n","        validation_data=val_generator,\n","        validation_steps=len(val_generator),\n","        verbose=2\n","    )\n","\n","    predictions = model.predict(val_generator, verbose=1)\n","    y_predictions = np.argmax(predictions, axis=1)\n","    true_classes = val_generator.classes\n","\n","    # evaluate validation performance\n","    print(\"*** Performance on Validation data ***\")\n","    val_acc, val_prec, val_fScore = my_metrics(true_classes, y_predictions)"]},{"cell_type":"markdown","metadata":{"id":"6HdmhXCj3ROr"},"source":["#Testing Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60037,"status":"ok","timestamp":1694052657368,"user":{"displayName":"murmayasa 2","userId":"06759457837881550460"},"user_tz":-480},"id":"2lrsr_093Xau","outputId":"6c45a849-84f2-4a13-ed27-873d3e099a23"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hasil Fold :  1\n","Found 811 validated image filenames belonging to 4 classes.\n","26/26 [==============================] - 10s 393ms/step - loss: 0.1653 - accuracy: 0.9174\n","26/26 [==============================] - 4s 140ms/step\n","*** Performance on Testing data ***\n","Accuracy  : 0.9173859432799013\n","Precision : 0.9299296886899454\n","f1Score : 0.9167237147599102\n","[[130   3   0   0]\n"," [  7 130   0   0]\n"," [  0   0 266   0]\n"," [  0   0  57 218]]\n","Hasil Fold :  2\n","Found 811 validated image filenames belonging to 4 classes.\n","26/26 [==============================] - 3s 112ms/step - loss: 0.1636 - accuracy: 0.9223\n","26/26 [==============================] - 3s 129ms/step\n","*** Performance on Testing data ***\n","Accuracy  : 0.9223181257706535\n","Precision : 0.9327735095568715\n","f1Score : 0.9219078733990393\n","[[132   1   0   0]\n"," [ 14 123   0   0]\n"," [  0   0 266   0]\n"," [  0   0  48 227]]\n","Hasil Fold :  3\n","Found 811 validated image filenames belonging to 4 classes.\n","26/26 [==============================] - 3s 108ms/step - loss: 0.1555 - accuracy: 0.9223\n","26/26 [==============================] - 3s 104ms/step\n","*** Performance on Testing data ***\n","Accuracy  : 0.9223181257706535\n","Precision : 0.9322122425115607\n","f1Score : 0.9219367272339317\n","[[131   2   0   0]\n"," [ 14 123   0   0]\n"," [  0   0 266   0]\n"," [  0   0  47 228]]\n","Hasil Fold :  4\n","Found 811 validated image filenames belonging to 4 classes.\n","26/26 [==============================] - 3s 120ms/step - loss: 0.1588 - accuracy: 0.9236\n","26/26 [==============================] - 3s 111ms/step\n","*** Performance on Testing data ***\n","Accuracy  : 0.9235511713933415\n","Precision : 0.9347364863575901\n","f1Score : 0.923085424587586\n","[[133   0   0   0]\n"," [ 11 127   0   0]\n"," [  0   0 265   0]\n"," [  0   0  51 224]]\n","Hasil Fold :  5\n","Found 811 validated image filenames belonging to 4 classes.\n","26/26 [==============================] - 3s 114ms/step - loss: 0.1469 - accuracy: 0.9359\n","26/26 [==============================] - 3s 115ms/step\n","*** Performance on Testing data ***\n","Accuracy  : 0.935881627620222\n","Precision : 0.9435489294922095\n","f1Score : 0.935641872693896\n","[[132   1   0   0]\n"," [  7 131   0   0]\n"," [  1   0 265   0]\n"," [  0   0  43 231]]\n"]}],"source":["class_labels = [cataract_dir, normal_dir]\n","skf = StratifiedKFold(n_splits=5, shuffle=True)\n","\n","fold_num = 0\n","test_losses = []\n","test_accuracies = []\n","confusion_matrices = []\n","\n","for train_index, test_index in skf.split(train_val_paths, train_val_labels):\n","    fold_num += 1\n","    print(\"Hasil Fold : \", fold_num)\n","    X_train, X_test = np.array(train_val_paths)[train_index], np.array(train_val_paths)[test_index]\n","    Y_train, Y_test = np.array(train_val_labels)[train_index], np.array(train_val_labels)[test_index]\n","\n","    for each_index in range(len(X_test)):\n","        class_label = ''\n","        for i in range(len(class_labels)):\n","            if Y_test[each_index] == str(i):\n","                class_label = class_labels[i]\n","        shutil.move(\n","            os.path.join(base_dir, 'latih', class_label, X_test[each_index]),\n","            os.path.join(base_dir, 'test', class_label, X_test[each_index])\n","        )\n","\n","    test_datagen = ImageDataGenerator(\n","        # rescale=1./225\n","        )\n","    test_labels = [str(label) for label in Y_test]\n","\n","    test_generator = test_datagen.flow_from_dataframe(\n","        pd.DataFrame({'image_path': X_test, 'label': test_labels}),\n","        x_col='image_path',\n","        y_col='label',\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode='categorical',\n","        shuffle=False\n","    )\n","\n","    test_loss, test_acc = model.evaluate(\n","        test_generator,\n","        steps=len(test_generator),\n","        verbose=1\n","    )\n","\n","    test_losses.append(test_loss)\n","    test_accuracies.append(test_acc)\n","\n","    predictions = model.predict(test_generator, verbose=1)\n","    y_predictions = np.argmax(predictions, axis=1)\n","    true_classes = test_generator.classes\n","\n","    # evaluate performance on testing data\n","    print(\"*** Performance on Testing data ***\")\n","    test_acc, test_prec, test_fScore = my_metrics(true_classes, y_predictions)\n","    confusion_matrices.append(confusion_matrix(true_classes, y_predictions))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}